{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.451619591 1.192596599\n"
     ]
    }
   ],
   "source": [
    "#get threshold of TNFalpha and CD107a\n",
    "threshold = pd.read_csv('./marker_threshold.csv', sep=',')\n",
    "for c in threshold.columns:\n",
    "    threshold = threshold.rename(columns={c: c.split(\"_\")[0]})\n",
    "thres1 = threshold.loc[0, 'TNFa']\n",
    "thres2 = threshold.loc[0, 'CD107a']\n",
    "print(thres1, thres2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['hr_start']      = []\n",
    "data['hr_end']        = []\n",
    "data['ratio']         = []\n",
    "data['size']          = []\n",
    "data['type']          = []\n",
    "data['mean_accuracy'] = []\n",
    "data['std']           = []\n",
    "data['roc-auc']       = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "hr_start = 5\n",
    "hr_end   = 8\n",
    "o_ratio  = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "for num, time in enumerate(range(hr_start, hr_end + 1)):\n",
    "    if not num : \n",
    "        df_0 = pd.read_csv(f'NK_Cell/transformedtxt/IL2/{time}hr_IL2_panel1.fcs_spill_applied_Ungated.txt', sep='\\t', skiprows=1, index_col=False)\n",
    "        dfs  = [df_0]\n",
    "    else:\n",
    "        new_df_0 = pd.read_csv(f'NK_Cell/transformedtxt/IL2/{time}hr_IL2_panel1.fcs_spill_applied_Ungated.txt', sep='\\t', skiprows=1, index_col=False)\n",
    "        dfs.append(new_df_0)\n",
    "df_0 = pd.concat(dfs).reset_index(drop=True)    \n",
    "df_0 = df_0.drop(\"Event #\", axis=1)\n",
    "for c in df_0.columns:\n",
    "    df_0 = df_0.rename(columns={c: c.split(\"_\")[0]})\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# impute negative as 0 \n",
    "df_0[df_0 < 0] = 0\n",
    "# drop unused responses\n",
    "targets = ['IFNg', 'IL3', 'MIP1a', 'GMCSF', 'MIP1b']\n",
    "df_0    = df_0.drop(targets, axis=1)\n",
    "c_list  = ['CD57', 'CD2', 'NKG2A', 'CD16', 'CD94', 'CD45RA', 'NKp30', 'CRACC', 'CRTAM', 'CD56', 'CD45', 'DNAM1', 'NKp46', 'CD161', 'CD8', 'NKG2C', 'CD96', 'LILRB1', 'KLRG1', 'DAP12', 'SAP', 'LAIR1', 'CD7', 'TIGIT', 'CD69', 'NKG2D', 'CD11a', 'EAT2', 'NTB', '2B4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by ratio\n",
    "df_0_  = df_0.assign(odds=0)\n",
    "df_0_['odds'] = (df_0_['TNFa']/thres1+0.0001)/(df_0_['CD107a']/thres2+0.0001)\n",
    "E  = df_0_[((df_0_['odds'] >= o_ratio) & (df_0_['TNFa'] >= thres1))].dropna(axis=1).drop(['odds'], axis=1)\n",
    "F  = df_0_[(df_0_['odds'] <= 1/o_ratio) & (df_0_['CD107a'] >= thres2)].dropna(axis=1).drop(['odds'], axis=1)\n",
    "E  = E.assign(label = 'TNFa')\n",
    "F  = F.assign(label = 'CD107a')\n",
    "EF = pd.concat([E, F])  \n",
    "EF = shuffle(EF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct training set\n",
    "dropped  = ['CD107a', 'TNFa', 'label']\n",
    "features = EF.drop(dropped, axis=1).columns\n",
    "N02 = EF.index\n",
    "X02 = EF.drop(dropped, axis=1).values\n",
    "y02 = EF['label'].values.copy()\n",
    "y02[y02 == 'TNFa']   = 0\n",
    "y02[y02 == 'CD107a'] = 1\n",
    "y02 = y02.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve setup\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xticks(rotation=0, fontsize=20)\n",
    "plt.yticks(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost\n",
    "print(\"- XGboost -\")\n",
    "feature_names = [x for x in df_0.columns if x not in dropped + ['label', 'label_response', 'Event #']]\n",
    "kf = KFold(n_splits = 5)\n",
    "for (num, (X, y)) in enumerate(zip([X02], [y02])):\n",
    "    print(\"dataset : \", num, len(X))\n",
    "    acc          = []\n",
    "    dm_acc       = []\n",
    "    all_tpr      = []\n",
    "    all_auroc    = []\n",
    "    max_accuracy = 0\n",
    "    for (f, (train_index, test_index)) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        dtrain = xgb.DMatrix(data = X_train, label = y_train, feature_names = feature_names)\n",
    "        dtest  = xgb.DMatrix(data = X_test, label = y_test, feature_names = feature_names)\n",
    "        param  = {'objective': 'binary:logistic', 'nthread': 1, 'eval_metric': ['error', 'auc'], 'booster': 'gbtree'}\n",
    "        # train XGBoost\n",
    "        clf    = xgb.train(param, dtrain, verbose_eval=False, early_stopping_rounds=2, evals=[(dtest, 'test')])\n",
    "        y_test = dtest.get_label()\n",
    "        preds  = clf.predict(dtest)\n",
    "        predictions   = [round(value) for value in preds]\n",
    "        test_accuracy = accuracy_score(y_test, predictions).round(3)\n",
    "        print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "        acc.append(test_accuracy)\n",
    "        if accuracy >= max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "        # plot XGboost importance\n",
    "        ax  = xgb.plot_importance(clf, importance_type='gain')\n",
    "        fig = ax.figure\n",
    "        fig.set_size_inches(10, 8)\n",
    "        ax.figure.tight_layout()\n",
    "        ax.figure.savefig(f'XGB_importance.png', dpi=300)\n",
    "        # save iteration ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "        all_tpr.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        auroc  = roc_auc_score(y_test, predictions)\n",
    "        all_auroc.append(auroc)\n",
    "    # caculate mean ROC\n",
    "    mean_tpr = np.mean(all_tpr, axis=0)\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'XGboost (AUROC={np.mean(all_auroc)})')\n",
    "    data['hr_start'].append(hr_start)\n",
    "    data['hr_end'].append(hr_end)\n",
    "    data['ratio'].append(o_ratio)\n",
    "    data['size'].append(len(EF))\n",
    "    data['type'].append(\"XGB\")\n",
    "    data['mean_accuracy'].append(np.mean(acc))\n",
    "    data['std'].append(np.std(acc))\n",
    "    data['roc-auc'].append(np.mean(all_auroc))\n",
    "    print(f\"MEAN ACC : {np.mean(acc)}\")\n",
    "    print(f\"STD : {np.std(acc)}\")\n",
    "    print(f\"MEAN AUROC: {np.mean(all_auroc)}\")\n",
    "    # plot ROCs\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title(f'ROC curve')\n",
    "    plt.legend(loc='best', fontsize='xx-large')\n",
    "    plt.savefig(f\"*Normalized/*ROC_{hr_start}_{hr_end}_{o_ratio}.png\", dpi=300)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
